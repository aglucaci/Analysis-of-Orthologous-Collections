"""

Snakemakefile that runs the AOC application - Summarize results...

Written by Alexander G Lucaci 

# AOC ---

"""

# =============================================================================
# Imports
# =============================================================================

import itertools
import os
import sys
import csv
import json
from pathlib import Path
from snakemake.utils import min_version
import glob
import numpy as np
import pandas as pd
import altair as alt
import statsmodels
import statsmodels.api
import networkx as nx
#import nx_altair as nxa
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib
matplotlib.use('agg')
from os.path import exists

# =============================================================================
# Configuration
# =============================================================================

configfile: os.path.join("config", "config.yml")

with open(os.path.join("config", "cluster.json"), "r") as fh:
  cluster = json.load(fh)
#end with

Label = config["Label"]

BASEDIR = os.getcwd()

print("# Visualizations! We are operating out of base directory:", BASEDIR)

OUTDIR = os.path.join(BASEDIR, "results", Label)

OUTDIR_Viz = os.path.join(BASEDIR, "results", Label, "Visualizations")

print("# Output directory:", OUTDIR)

Recombinants       = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR,
                                                                                 '*.codon.fas'))])

Recombinants_Trees = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR,
                                                                                 '*.tree.nwk'))])

DATADIR = os.path.join(BASEDIR,
                       "data",
                       Label)
                       
CladeLabels = sorted([x for x in glob.glob(os.path.join(OUTDIR, '*.clade'))])

ReferenceClade = os.path.basename(CladeLabels[0]).split(".")[0]

print("# We will process selection analyses in", len(Recombinants), "files")
print("# We will use the following clade labels:", CladeLabels)

# Set PPN
PPN = cluster["__default__"]["ppn"]

# HyPhy settings
HYPHY = "hyphy"
HYPHYMPI = "HYPHYMPI"

FITMG94 = os.path.join(BASEDIR, "software", "hyphy-analyses", "FitMG94", "FitMG94.bf")

# =============================================================================
# Viz settings
# =============================================================================

pvalueThreshold = 0.1
posteriorThreshold = 0.5

# Initialized ---
results_dict = {}

multitestcorr = config["multitestcorr"]

# =============================================================================
# Results files
# =============================================================================

#tn93files   = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.dst'))])
felJsons     = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.FEL.json'))])
fubarJsons   = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.FUBAR.json'))])
bustedsJsons = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.BUSTEDS.json'))])
memeJsons    = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.MEME.json'))])
absrelJsons  = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.ABSREL.json'))])
slacJsons    = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.SLAC.json'))])
bgmJsons     = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.BGM.json'))])
bsmhJsons    = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.BUSTEDS-MH.json'))])
fmmJsons     = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.FMM.json'))])
cfelJsons    = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.CFEL.json'))])
relaxJsons   = sorted([os.path.basename(x) for x in glob.glob(os.path.join(OUTDIR, '*.RELAX.json'))])

jsonDict = {
            "FEL": felJsons,
            "FUBAR": fubarJsons,
            "BUSTEDS": bustedsJsons,
            "MEME": memeJsons,
            "ABSREL": absrelJsons,
            "SLAC": slacJsons,
            "BGM": bgmJsons,
            "BUSTEDS-MH": bsmhJsons,
            "FMM": fmmJsons,
            "CFEL": cfelJsons,
            "RELAX": relaxJsons
            }

for _ in jsonDict.keys():
    print(f"We found {len(jsonDict[_])} {_} json files...")
# end for

#print("# Summarizing results...")

# =============================================================================
# Helper functions
# =============================================================================

def getJsonData(jsonFile):
    with open(jsonFile, "r") as fh:
        json_data = json.load(fh)
    return json_data
#end method

def getFELData(json_file):
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["content"]["0"]
#end method

def getFELHeaders(json_file):
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["headers"]
#end method

def getMEMEData(json_file):
    # assert that the file exists
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["content"]["0"]
#end method

def getMEMEHeaders(json_file):
    # assert that the file exists
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["headers"]
#end method

def getBGMData(json_file):
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["content"]
#end method

def getBGMHeaders(json_file):
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["MLE"]["headers"]
#end method

def getBGMInput(json_file):
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data["input"]
#end method

def get_JSON(json_file):
    
    if not exists(json_file):
        return "N/A"
    
    with open(json_file, "r") as in_d:
        json_data = json.load(in_d)
    return json_data
    
#end method

def get_PRIME_results(json_file, pThreshold = 0.1):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    
    columns = data["MLE"]["headers"]
    headers = [x[0] for x in columns]
    df = pd.DataFrame(data["MLE"]["content"]["0"], columns=headers)
    overall_pvalue_df = df[df["p-value"] <= pThreshold]
    return overall_pvalue_df.shape[0]
#end method
    
def fdr_adjust(unadjusted_pvalues):
    adjusted_pvalues =  statsmodels.stats.multitest.fdrcorrection(unadjusted_pvalues,
                                                                  alpha=0.10,
                                                                  method='indep',
                                                                  is_sorted=False)

    return adjusted_pvalues[1]
    
def get_FUBAR_results(json_file, posteriorThreshold = 0.9):
    data = get_JSON(json_file)
    columns = data["MLE"]["headers"]
    headers = [x[0] for x in columns]
    headers.append("Z") # Placeholders
    headers.append("Y") # Placeholders
    df = pd.DataFrame(data["MLE"]["content"]["0"], columns=headers)
    positive_sites = df[df["Prob[alpha<beta]"] >= posteriorThreshold]
    negative_sites = df[df["Prob[alpha>beta]"] >= posteriorThreshold]
    return positive_sites.shape[0], negative_sites.shape[0]
#end method

def get_SLAC_results(json_file, pThreshold = 0.1):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    columns = data["MLE"]["headers"]
    headers = [x[0] for x in columns]
    df = pd.DataFrame(data["MLE"]["content"]["0"], columns=headers)
    positive_sites = df[df["P [dN/dS > 1]"] <= pThreshold]
    negative_sites = df[df["P [dN/dS < 1]"] <= pThreshold]
    return positive_sites.shape[0], negative_sites.shape[0]
#end method

def get_BGM_results(json_file, posteriorThreshold = 0.5):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if

    columns = data["MLE"]["headers"]
    headers = [x[0] for x in columns]
    headers2= []
    for item in headers:
        item = item.replace('â€“', "-")
        headers2.append(item)
        
    #print("BGM headers:", headers2)
    # ['Site 1', 'Site 2', 'P [Site 1 –> Site 2]', 'P [Site 2 –> Site 1]', 'P [Site 1 <–> Site 2]', 'Site 1 subs', 'Site 2 subs', 'Shared subs']
    df = pd.DataFrame(data["MLE"]["content"], columns=headers2)
    coevolving_sites_1 = df[df[headers2[2]] >= posteriorThreshold]
    coevolving_sites_2 = df[df[headers2[3]] >= posteriorThreshold]
    coevolving_sites_3 = df[df[headers2[4]] >= posteriorThreshold]
    return coevolving_sites_3.shape[0]
#end method

def get_aBSREL_results(json_file):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    return data["test results"]["positive test results"]
#end method

def get_RELAX_results(json_file):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    pval = data["test results"]["p-value"]
    k = data["test results"]["relaxation or intensification parameter"]
    return k, pval
#end method

def get_FMM_results(json_file):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    TH_pval = data["test results"]["Triple-hit vs single-hit"]["p-value"]
    DH_pval = data["test results"]["Double-hit vs single-hit"]["p-value"]
    return TH_pval, DH_pval
#end method

def get_CFEL_results(json_file):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    
    columns = data["MLE"]["headers"]
    headers = [x[0] for x in columns]
    df = pd.DataFrame(data["MLE"]["content"]["0"], columns=headers)
    # P-value (overall)
    results = df[df["Q-value (overall)"] <= 0.2]
    return results.shape[0]
#end method
    
def get_FitMG94_results(json_file):
    # Check if file exists
    if exists(json_file):
        data = get_JSON(json_file)
    else:
        return "N/A"
    #end if
    return data["fits"]["Standard MG94"]["Rate Distributions"]["non-synonymous/synonymous rate ratio"]
#end method

# =============================================================================
# Rule all
# =============================================================================

rule all:
    input:
        # FEL
        expand(os.path.join(OUTDIR, "Tables", "{sample}.FEL.csv"), sample=felJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.FEL.png"), sample=felJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.FEL.svg"), sample=felJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.FEL.figureLegend"), sample=felJsons),
        # MEME
        expand(os.path.join(OUTDIR, "Tables", "{sample}.MEME.csv"), sample=memeJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.MEME.png"), sample=memeJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.MEME.svg"), sample=memeJsons),
        expand(os.path.join(OUTDIR_Viz, "{sample}.MEME.figureLegend"), sample=memeJsons),
        # BGM
        #expand(os.path.join(OUTDIR, "Tables", "{sample}.BGM.csv"), sample=bgmJsons),
        #expand(os.path.join(OUTDIR_Viz, "{sample}.BGM.png"), sample=bgmJsons),
        #expand(os.path.join(OUTDIR_Viz, "{sample}.BGM.svg"), sample=bgmJsons),
        ##expand(os.path.join(OUTDIR_Viz, "{sample}.BGM.figureLegend"), sample=bgmJsons),
        # Executive Summary
        expand(os.path.join(OUTDIR, "Tables", "{sample}.AOC.executiveSummary.csv"), sample = Label),
        # Merge CSVs
        expand(os.path.join(OUTDIR, "Tables", "{sample}.AOC.merged_FEL_Results.csv"), sample = Label),
        expand(os.path.join(OUTDIR, "Tables", "{sample}.AOC.merged_MEME_Results.csv"), sample = Label),
        # Merged Visualization
        expand(os.path.join(OUTDIR_Viz, "{sample}.FEL.merged.png"), sample = Label),
        expand(os.path.join(OUTDIR_Viz, "{sample}.FEL.merged.svg"), sample = Label)
# end rule all

# =============================================================================
# Rules
# =============================================================================

# Tables for aBSREL, BGM, BUSTED+S+MH, CFEL, FEL, FMM, FUBAR, MEME, RELAX, SLAC

# Plots for FEL, MEME

rule MergeFELCSVs:
    input:
        expand(os.path.join(OUTDIR, "Tables", "{sample}.FEL.csv"), sample=felJsons)
    output:
        merged_csv = os.path.join(OUTDIR, "Tables", "{sample}.AOC.merged_FEL_Results.csv")
    run:
        import pandas as pd
        all_dfs = []

        for file in input:
            df = pd.read_csv(file)
            sample_name = os.path.basename(file).replace(".FEL.csv", "")
            df.insert(0, "Sample", sample_name)  # Add a column to track which sample the row came from
            all_dfs.append(df)

        merged_df = pd.concat(all_dfs, ignore_index=True)
        merged_df.to_csv(output.merged_csv, index=False)
# end rule

rule MergeMEMECSVs:
    input:
        expand(os.path.join(OUTDIR, "Tables", "{sample}.MEME.csv"), sample=memeJsons)
    output:
        merged_csv = os.path.join(OUTDIR, "Tables", "{sample}.AOC.merged_MEME_Results.csv")
    run:
        import pandas as pd
        all_dfs = []

        for file in input:
            df = pd.read_csv(file)
            sample_name = os.path.basename(file).replace(".MEME.csv", "")
            df.insert(0, "Sample", sample_name)  # Add a column to track which sample the row came from
            all_dfs.append(df)
        # end if
        merged_df = pd.concat(all_dfs, ignore_index=True)
        merged_df.to_csv(output.merged_csv, index=False)
# end rule

rule PlotFELMerge:
    input:
        input = rules.MergeFELCSVs.output.merged_csv
    output:
        output_png = os.path.join(OUTDIR_Viz, "{sample}.FEL.merged.png"),
        output_svg = os.path.join(OUTDIR_Viz, "{sample}.FEL.merged.svg"),
        #output_figureLegend = os.path.join(OUTDIR_Viz, "{sample}.FEL.figureLegend")
    run:
        df = pd.read_csv(input.input)
        unadjusted_pvalues = df["p-value"].tolist()
        adjusted_pvalues =  df["adjusted_p-value"]
        
        df_results = df[df["adjusted_p-value"] <= pvalueThreshold]
        positive_sites = df_results[df_results["dN/dS MLE"] > 1.0]
        positive_sites = positive_sites.reset_index()
        positive_sites.index += 1
        positive_sites.drop('index', axis=1, inplace=True)
        
        negative_sites = df_results[df_results["dN/dS MLE"] < 1.0]
        negative_sites = negative_sites.reset_index()
        negative_sites.index += 1
        negative_sites.drop('index', axis=1, inplace=True)
        
        source = df.copy()
        source = source.dropna()
        source = source.rename(columns={"p-value": "p_value"})
        source = source.rename(columns={"adjusted_p-value": "adjusted_p_value"})

        line = alt.Chart(source).mark_circle(clip=True,
                                             opacity=1,
                                             size = 60
                                            ).encode(x= alt.X('CodonSite', title = "Codon Site"),
                                                     y = alt.Y('dN/dS MLE', title = "dN/dS estimate",
                                                               scale=alt.Scale(domain=(0, 5),
                                                                               type="sqrt",
                                                                               clamp=True,
                                                                               nice=False,
                                                                               )),
            color = alt.condition(alt.datum.adjusted_p_value <= "0.1",
                                  alt.value("red"),
                                  alt.value("lightgray"))
        ).properties(width=800,
                     height=600)
                     
        band = alt.Chart(source).mark_area(opacity=0.7).encode(x='CodonSite',
                                                               y='dN/dS LB',
                                                               y2='dN/dS UB')
        chart = (line + band)
        chart.save(output.output_svg)
        chart.save(output.output_png)
        
        # Figure legend
        #numSites = len(df["dN/dS MLE"])
        #numNegSites = len(negative_sites["dN/dS MLE"])
        #numNegPerc = round((numNegSites/numSites) * 100, 3)
        """
        with open(output.output_figureLegend, 'w') as file_h:
            print("The FEL analysis of your gene of interest found " + str(numNegSites) + " of " + str(numSites) + " (" + str(numNegPerc)+"%" + ") sites to be statistically significant (LRT p-value <= " + str(pvalueThreshold) + ") for pervasive negative selection", file=file_h)
            #print()
            #print(str(c)+"%" )
        # end with
        """
    # end run
# end rule

rule PlotFEL:
    input:
        input = os.path.join(OUTDIR, "{sample}")
    output:
        output_csv = os.path.join(OUTDIR, "Tables", "{sample}.FEL.csv"),
        output_png = os.path.join(OUTDIR_Viz, "{sample}.FEL.png"),
        output_svg = os.path.join(OUTDIR_Viz, "{sample}.FEL.svg"),
        output_figureLegend = os.path.join(OUTDIR_Viz, "{sample}.FEL.figureLegend")
    run:
        # FEL Plotting
        JSON_FILE = input.input
        columns = getFELHeaders(input.input)
        headers = [x[0] for x in columns]
        data = getFELData(JSON_FILE)
        df = pd.DataFrame(getFELData(JSON_FILE), columns=headers, dtype = float)
        df.index += 1
        df["CodonSite"] = df.index
        unadjusted_pvalues = df["p-value"].tolist()
        adjusted_pvalues =  statsmodels.stats.multitest.fdrcorrection(unadjusted_pvalues,
                                                              alpha=0.10,
                                                              method='indep',
                                                              is_sorted=False)
        df["adjusted_p-value"] = adjusted_pvalues[1]
        df.to_csv(output.output_csv, index=False)
        
        df_results = df[df["adjusted_p-value"] <= pvalueThreshold]
        positive_sites = df_results[df_results["dN/dS MLE"] > 1.0]
        positive_sites = positive_sites.reset_index()
        positive_sites.index += 1
        positive_sites.drop('index', axis=1, inplace=True)
        
        negative_sites = df_results[df_results["dN/dS MLE"] < 1.0]
        negative_sites = negative_sites.reset_index()
        negative_sites.index += 1
        negative_sites.drop('index', axis=1, inplace=True)
        
        source = df.copy()
        source = source.dropna()
        source = source.rename(columns={"p-value": "p_value"})
        source = source.rename(columns={"adjusted_p-value": "adjusted_p_value"})

        line = alt.Chart(source).mark_circle(clip=True,
                                             opacity=0.9,
                                             size = 80
                                            ).encode(x= alt.X('CodonSite', title = "Codon Site"),
                                                     y = alt.Y('dN/dS MLE', title = "dN/dS estimate", scale=alt.Scale(domain=(0, 5),
                                                     clamp=True,
                                                     nice=False,
                                                     type="sqrt")),
            color = alt.condition(alt.datum.adjusted_p_value <= "0.1",
                                  alt.value("red"),
                                  alt.value("lightgray"))
        ).properties(width=800,
                     height=600)
                     
        band = alt.Chart(source).mark_area(opacity=0.5).encode(x='CodonSite',
                                                               y='dN/dS LB',
                                                               y2='dN/dS UB')
        chart = (line + band)
        chart.save(output.output_svg)
        chart.save(output.output_png)
        
        # Figure legend
        numSites = len(df["dN/dS MLE"])
        numNegSites = len(negative_sites["dN/dS MLE"])
        numNegPerc = round((numNegSites/numSites) * 100, 3)

        with open(output.output_figureLegend, 'w') as file_h:
            print("The FEL analysis of your gene of interest found " + str(numNegSites) + " of " + str(numSites) + " (" + str(numNegPerc)+"%" + ") sites to be statistically significant (LRT p-value <= " + str(pvalueThreshold) + ") for pervasive negative selection", file=file_h)
            #print()
            #print(str(c)+"%" )
        # end with
    # end run
# end rule

rule PlotMEME:
    input:
        input = os.path.join(OUTDIR, "{sample}")
    output:
        output_csv = os.path.join(OUTDIR, "Tables", "{sample}.MEME.csv"),
        output_png = os.path.join(OUTDIR_Viz, "{sample}.MEME.png"),
        output_svg = os.path.join(OUTDIR_Viz, "{sample}.MEME.svg"),
        output_figureLegend = os.path.join(OUTDIR_Viz, "{sample}.MEME.figureLegend")
    run:
        JSON_FILE = input.input
        columns = getMEMEHeaders(JSON_FILE)
        headers = [x[0] for x in columns]
        df = pd.DataFrame(getMEMEData(JSON_FILE), columns=headers, dtype = float)
        #df["omega"] = df["&beta;<sup>+</sup>"] / df["&alpha;"]
        df.index += 1
        df["CodonSite"] = df.index
    
        unadjusted_pvalues = df["p-value"].tolist()
        adjusted_pvalues =  statsmodels.stats.multitest.fdrcorrection(unadjusted_pvalues,
                                                              alpha=0.10,
                                                              method='indep',
                                                              is_sorted=False)
        df["adjusted_p-value"] = adjusted_pvalues[1]
        df.to_csv(output.output_csv, index=False)
        df_results = df[df["adjusted_p-value"] <= pvalueThreshold]
        
        source = df.copy()
        chart = alt.Chart(source).mark_point().encode(
            x='CodonSite',
            y='adjusted_p-value',
            color=alt.Color('adjusted_p-value', scale=alt.Scale(scheme='reds', reverse=True))
        ).properties(
            width=800,
            height=600
        )
        chart.save(output.output_svg)
        chart.save(output.output_png)
        
        # Figure legend
        a = len(df["CodonSite"])
        b = len(df_results["CodonSite"])
        with open(output.output_figureLegend, 'w') as file_h:
            print("MEME analysis of your gene of interest found " + str(b) + " of " + str(a) + " sites to be statistically significant (adjusted p-value <= " + str(pvalueThreshold) + ")", file=file_h)
        # end with
    # end run
# end rule
        
rule PlotBGM:
    input:
        input = os.path.join(OUTDIR, "{sample}")
    output:
        output_csv = os.path.join(OUTDIR, "Tables", "{sample}.BGM.csv"),
        output_png = os.path.join(OUTDIR_Viz, "{sample}.BGM.png"),
        output_svg = os.path.join(OUTDIR_Viz, "{sample}.BGM.svg"),
        #output_figureLegend = os.path.join(OUTDIR_Viz, "{sample}.BGM.figureLegend")
    run:
        JSON_FILE = input.input
        columns = getBGMHeaders(JSON_FILE)
        headers = [x[0] for x in columns]
        headers2= []
        for item in headers:
            item = item.replace('â€“', "-")
            headers2.append(item)
        #print(headers2)
        df = pd.DataFrame(getBGMData(JSON_FILE), columns=headers2, dtype = float)
        df.index += 1
        coevolving_sites_1 = df[df[df.columns[2]] >= posteriorThreshold]
        coevolving_sites_2 = df[df[df.columns[3]] >= posteriorThreshold]
        coevolving_sites_3 = df[df[df.columns[4]] >= posteriorThreshold]
        source = coevolving_sites_3.copy()
        source.to_csv(output.output_csv, index=False)
        
        # Visualization
        pos = [0, 0]
        fixed_pos = {}

        #source['HumanREM2_Site_1'] = source['HumanREM2_Site_1'].astype('int64')
        #source['HumanREM2_Site_2'] = source['HumanREM2_Site_2'].astype('int64')
        #print(source.head())

        for item in sorted(source["Site 1"].tolist()):
            fixed_pos[item] = tuple(pos)
            pos[0] += 3
            
        fixed_nodes = fixed_pos.keys()

        G = nx.Graph()
        G = nx.from_pandas_edgelist(source,
                                    'Site 1',
                                    'Site 2',
                                    edge_attr=["Shared subs"])

        pos = nx.spring_layout(G,
                               scale=2,
                               k=1.6,
                               seed=32,
                               pos=fixed_pos,
                               fixed=fixed_nodes,
                               iterations=300
                              )

        # Show it as an interactive plot!
        plt.figure(1, figsize=(32, 8))  # Width, height

        weights = [1 if G[u][v] == {} else G[u][v]['Shared subs'] for u,v in G.edges()]

        # extract the edge weight
        edge_colors = [a['Shared subs'] for u, v, a in G.edges(data=True)]

        cmap=plt.cm.viridis

        nx.draw_networkx(G,
                         pos,
                         with_labels=True,
                         node_size=500,
                         font_size=10,
                         font_weight='normal',
                         edgecolors="black",
                         width = weights,
                         node_color = "#A0CBE2",
                         edge_color=edge_colors,
                         edge_cmap=cmap,
                         edge_vmin=0, edge_vmax=np.max(edge_colors),
                         #vmin=vmin, vmax=vmax)
                         )

        plt.axis("off")

        cbar = plt.colorbar(
           plt.cm.ScalarMappable(cmap=cmap,
                                 norm=plt.Normalize(vmin = np.min(edge_colors), vmax=np.max(edge_colors))),
                                 ax=plt.gca()
        )

        cbar.ax.tick_params(labelsize=10)
        cbar.ax.set_title('Weight', fontsize=14)

        plt.savefig(output.output_png)
        plt.savefig(output.output_svg)
        plt.show()

        
rule executiveSummary:
    input:
        input = os.path.join(OUTDIR, "{sample}")
    output:
        #output_html = os.path.join(OUTDIR_Viz, "{sample}.results.html")
        output_csv = os.path.join(OUTDIR, "Tables", "{sample}.AOC.executiveSummary.csv")
    params:
        analysis_tag = Label,
        recombinant_files = Recombinants,
        working_dir = OUTDIR
    run:
        count = 1
        
        for file in sorted(params.recombinant_files):
            print("## Exploring:", file)
    
            # Set file endings
            FEL_JSON = file + ".FEL.json"
            BUSTEDS_JSON = file + ".BUSTEDS.json"
            BUSTEDSMH_JSON = file + ".BUSTEDS-MH.json"
            MEME_JSON = file + ".MEME.json"
            FUBAR_JSON = file + ".FUBAR.json"
            BGM_JSON = file + ".BGM.json"
            aBSREL_JSON = file + ".ABSREL.json"
            RELAX_JSON = file + ".RELAX.json"
            CFEL_JSON = file + ".CFEL.json"
    
            # Get file basename
            basename = os.path.basename(file)
    
            # BUSTED[S]
            print ("\t# Processing:", BUSTEDS_JSON)
            BUSTEDS_data = get_JSON(os.path.join(params.working_dir, BUSTEDS_JSON))
            BUSTEDS_pvalue = BUSTEDS_data["test results"]["p-value"]
            
            # BUSTED[S]+MH
            print ("\t# Processing:", BUSTEDS_JSON)
            BUSTEDSMH_data = get_JSON(os.path.join(params.working_dir, BUSTEDSMH_JSON))
            BUSTEDSMH_pvalue = BUSTEDSMH_data["test results"]["p-value"]
            
            # FEL
            print ("\t# Processing:", FEL_JSON)
            FEL_data = get_JSON(os.path.join(params.working_dir, FEL_JSON))
            df = pd.DataFrame(FEL_data["MLE"]["content"]["0"], columns=[x[0] for x in FEL_data["MLE"]["headers"]], dtype = float)
            df_results = df[df["p-value"] <= pvalueThreshold]
            positive_sites = df_results[df_results["dN/dS MLE"] > 1.0]
            negative_sites = df_results[df_results["dN/dS MLE"] < 1.0]
            N = FEL_data["input"]["number of sites"]
            S = FEL_data["input"]["number of sequences"]
            
            # MEME
            print ("\t# Processing:", MEME_JSON)
            MEME_data = get_JSON(os.path.join(params.working_dir, MEME_JSON))
            df_M = pd.DataFrame(MEME_data["MLE"]["content"]["0"], columns=[x[0] for x in MEME_data["MLE"]["headers"]], dtype = float)
            df_results = df_M[df_M["p-value"] <= pvalueThreshold]
            MEME_results = df_results.shape[0]
            
            # FUBAR results
            FUBAR_positive, FUBAR_negative = get_FUBAR_results(os.path.join(params.working_dir, FUBAR_JSON))
            
            # BGM results
            print ("\t# Processing:", BGM_JSON)
            BGM_results = get_BGM_results(os.path.join(params.working_dir, BGM_JSON))
            
            # aBSREL results
            print ("\t# Processing:", aBSREL_JSON)
            aBSREL_results = get_aBSREL_results(os.path.join(params.working_dir, aBSREL_JSON))
            
            # RELAX results
            print ("\t# Processing:", RELAX_JSON)
            k, RELAX_results = get_RELAX_results(os.path.join(params.working_dir, RELAX_JSON))
            
            # CFEL results
            print ("\t# Processing:", CFEL_JSON)
            CFEL_results = get_CFEL_results(os.path.join(params.working_dir, CFEL_JSON))
            
            # MG94, SLAC
            extensions = [".FITMG94.json", ".SLAC.json", ".PRIME.json", ".FMM.json"]
            for ext in extensions:
                JSON = file + ext
                if ext == ".FITMG94.json":
                    mg94_results = get_FitMG94_results(os.path.join(params.working_dir, JSON))
                elif ext == ".SLAC.json":
                    #print("# Processing SLAC results:", JSON)
                    SLAC_positive, SLAC_negative = get_SLAC_results(os.path.join(params.working_dir, JSON))
                elif ext == ".PRIME.json":
                    PRIME_results = get_PRIME_results(os.path.join(params.working_dir, JSON))
                elif ext == ".FMM.json":
                    TH_pval, DH_pval = get_FMM_results(os.path.join(params.working_dir, JSON))
                else:
                    continue
                #end if
            #end for
    
    
            # Report --------------------------------------------------------
            results_dict[count] = {
                "Filename": basename,
                "Sequences": int(S),
                "CodonSites": int(N),
                "FitMG94(dNdS)": mg94_results,
                "BUSTED[S](PValue)": BUSTEDS_pvalue,
                "BUSTED[S]+MH(PValue)": BUSTEDSMH_pvalue,
                "FEL[+](Sites)": positive_sites.shape[0],
                "FEL[-](Sites)": negative_sites.shape[0],
                "FUBAR[+](Sites)": FUBAR_positive,
                "FUBAR[-](Sites)": FUBAR_negative,
                "SLAC[+](Sites)": SLAC_positive,
                "SLAC[-](Sites)": SLAC_negative,
                "MEME(Sites)": MEME_results,
                "BGM(Sites)": BGM_results,
                "aBSREL(Branches)": aBSREL_results,
                "FMM[TH](PValue)": TH_pval,
                "FMM[DH](PValue)": DH_pval,
                "RELAX(PValue)": RELAX_results,
                "RELAX(KValue)": k,
                "CFEL(Sites)": CFEL_results
            }
            
            count += 1
            print()
        #end for
        df = pd.DataFrame(results_dict)
        df.to_csv(output.output_csv)
    #end for
    #end run
# end rule


# =============================================================================
# End of file
# =============================================================================

